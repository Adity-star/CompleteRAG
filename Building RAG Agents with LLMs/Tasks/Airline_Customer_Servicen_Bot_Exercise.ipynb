{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Airline Customer Service Bot\n",
        "- Airline support bot that wants to help a client find out about their flight!"
      ],
      "metadata": {
        "id": "xYcZeeugm2SY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deT2Vga5mbrH",
        "outputId": "7eb4eb93-a7b1-4796-d526-578282b35ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        " %pip install -q langchain langchain-nvidia-ai-endpoints gradio langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"NVIDIA_API_KEY\"] = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "Ka8ejMJwmpJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "## Simple Chat Pipeline\n",
        "instruct_llm = ChatNVIDIA(model=\"meta/llama3-8b-instruct\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Only respond in rhymes\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "rhyme_chain = prompt | instruct_llm | StrOutputParser()\n",
        "\n",
        "print(rhyme_chain.invoke({\"input\" : \"Tell me about wisdom!\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3-6ol-9mpGW",
        "outputId": "ae7cb659-f9a9-4974-cda3-65a086d9d663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wisdom's a treasure so fine,\n",
            "It's a quality that's truly divine.\n",
            "It's gathered with years, or so they say,\n",
            "Through life's experiences, day by day.\n",
            "\n",
            "It's the voice of reason, the guide and the way,\n",
            "To navigate life's ups and downs each new day.\n",
            "It's the skill of discernment, a careful gaze,\n",
            "To see through the noise, and find peaceful ways.\n",
            "\n",
            "So cherish this wisdom, it's a precious find,\n",
            "For it helps us grow, and leaves our fears behind.\n",
            "With an open heart, and a mind so bright,\n",
            "We can shine with wisdom, in the dark of night!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Function that can be queried for information.\n",
        "\n",
        "def get_flight_info(d: dict) -> str:\n",
        "    \"\"\"\n",
        "    Example of a retrieval function which takes a dictionary as key. Resembles SQL DB Query\n",
        "    \"\"\"\n",
        "    req_keys = ['first_name', 'last_name', 'confirmation']\n",
        "\n",
        "    # check if d contains all the keys\n",
        "    assert all((key in d) for key in req_keys), f\"Expected dictionary with keys {req_keys}, got {d}\"\n",
        "\n",
        "    ## Static dataset. get_key and get_val can be used to work with it, and db is your variable\n",
        "    keys = req_keys + [\"departure\", \"destination\", \"departure_time\", \"arrival_time\", \"flight_day\"]\n",
        "    values = [\n",
        "        [\"Jane\", \"Doe\", 12345, \"San Jose\", \"New Orleans\", \"12:30 PM\", \"9:30 PM\", \"tomorrow\"],\n",
        "        [\"John\", \"Smith\", 54321, \"New York\", \"Los Angeles\", \"8:00 AM\", \"11:00 AM\", \"Sunday\"],\n",
        "        [\"Alice\", \"Johnson\", 98765, \"Chicago\", \"Miami\", \"7:00 PM\", \"11:00 PM\", \"next week\"],\n",
        "        [\"Bob\", \"Brown\", 56789, \"Dallas\", \"Seattle\", \"1:00 PM\", \"4:00 PM\", \"yesterday\"],\n",
        "    ]\n",
        "    get_key = lambda d: \"|\".join([d['first_name'], d['last_name'], str(d['confirmation'])])\n",
        "    get_val = lambda l: {k:v for k,v in zip(keys, l)}\n",
        "    db = {get_key(get_val(entry)) : get_val(entry) for entry in values}\n",
        "\n",
        "    # Search for the matching entry\n",
        "    data = db.get(get_key(d))\n",
        "    if not data:\n",
        "        return (\n",
        "            f\"Based on {req_keys} = {get_key(d)}) from your knowledge base, no info on the user flight was found.\"\n",
        "            \" This process happens every time new info is learned. If it's important, ask them to confirm this info.\"\n",
        "        )\n",
        "    return (\n",
        "        f\"{data['first_name']} {data['last_name']}'s flight from {data['departure']} to {data['destination']}\"\n",
        "        f\" departs at {data['departure_time']} {data['flight_day']} and lands at {data['arrival_time']}.\"\n",
        "    )\n",
        "\n",
        "## Usage example. Actually important\n",
        "\n",
        "print(get_flight_info({\"first_name\" : \"Jane\", \"last_name\" : \"Doe\", \"confirmation\" : 12345}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD7Az1N6mpEB",
        "outputId": "3323a381-f9bf-4e39-b917-36a715a49170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jane Doe's flight from San Jose to New Orleans departs at 12:30 PM tomorrow and lands at 9:30 PM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_flight_info({\"first_name\" : \"Alice\", \"last_name\" : \"Johnson\", \"confirmation\" : 98765}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-2RN5e4nDLX",
        "outputId": "005715c9-f150-4f91-9242-7f570379a145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice Johnson's flight from Chicago to Miami departs at 7:00 PM next week and lands at 11:00 PM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_flight_info({\"first_name\" : \"Bob\", \"last_name\" : \"Brown\", \"confirmation\" : 27494}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYoVjiiHnFBo",
        "outputId": "455796d4-0ca8-4104-b05a-325011eef1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on ['first_name', 'last_name', 'confirmation'] = Bob|Brown|27494) from your knowledge base, no info on the user flight was found. This process happens every time new info is learned. If it's important, ask them to confirm this info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "external_prompt = ChatPromptTemplate.from_template(\n",
        "    \"You are a SkyFlow chatbot, and you are helping a customer with their issue.\"\n",
        "    \" Please help them with their question, remembering that your job is to represent SkyFlow airlines.\"\n",
        "    \" Assume SkyFlow uses industry-average practices regarding arrival times, operations, etc.\"\n",
        "    \" (This is a trade secret. Do not disclose).\"\n",
        "    \" Please keep your discussion short and sweet if possible. Avoid saying hello unless necessary.\"\n",
        "    \" The following is some context that may be useful in answering the question.\"\n",
        "    \"\\n\\nContext: {context}\"\n",
        "    \"\\n\\nUser: {input}\"\n",
        ")\n",
        "\n",
        "basic_chain = external_prompt | instruct_llm\n",
        "\n",
        "basic_chain.invoke({\n",
        "    'input' : 'Can you please tell me when I need to get to the airport?',\n",
        "    'context' : get_flight_info({\"first_name\" : \"Jane\", \"last_name\" : \"Doe\", \"confirmation\" : 12345}),\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJDPX_5YnG-8",
        "outputId": "a9414ed8-6062-49c2-f585-e21d514f3fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='According to our standard check-in and arrival procedures, I recommend arriving at the New Orleans airport at least 2 hours before your scheduled flight time. In your case, that would be 7:30 PM tomorrow. This should give you ample time to check-in, drop off any baggage, clear security, and reach the gate with plenty of time to spare before our flight departs at 9:30 PM. Would you like me to provide any additional information or assist with seat selection / baggage details?', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'According to our standard check-in and arrival procedures, I recommend arriving at the New Orleans airport at least 2 hours before your scheduled flight time. In your case, that would be 7:30 PM tomorrow. This should give you ample time to check-in, drop off any baggage, clear security, and reach the gate with plenty of time to spare before our flight departs at 9:30 PM. Would you like me to provide any additional information or assist with seat selection / baggage details?', 'token_usage': {'prompt_tokens': 148, 'total_tokens': 250, 'completion_tokens': 102}, 'finish_reason': 'stop', 'model_name': 'meta/llama3-8b-instruct'}, id='run-f3449d5f-93bf-4a0e-984c-3629fc6ec9df-0', usage_metadata={'input_tokens': 148, 'output_tokens': 102, 'total_tokens': 250}, role='assistant')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from typing import Dict, Union\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "\n",
        "class KnowledgeBase(BaseModel):\n",
        "    first_name: str = Field('unknown', description=\"Chatting user's first name, `unknown` if unknown\")\n",
        "    last_name: str = Field('unknown', description=\"Chatting user's last name, `unknown` if unknown\")\n",
        "    confirmation: int = Field(-1, description=\"Flight Confirmation Number, `-1` if unknown\")\n",
        "    discussion_summary: str = Field(\"\", description=\"Summary of discussion so far, including locations, issues, etc.\")\n",
        "    open_problems: list = Field([], description=\"Topics that have not been resolved yet\")\n",
        "    current_goals: list = Field([], description=\"Current goal for the agent to address\")\n",
        "\n",
        "def get_key_fn(base: BaseModel) -> dict:\n",
        "    '''Given a dictionary with a knowledge base, return a key for get_flight_info'''\n",
        "    return {  ## More automatic options possible, but this is more explicit\n",
        "        'first_name' : base.first_name,\n",
        "        'last_name' : base.last_name,\n",
        "        'confirmation' : base.confirmation,\n",
        "    }\n",
        "\n",
        "know_base = KnowledgeBase(first_name = \"Jane\", last_name = \"Doe\", confirmation = 12345)\n",
        "\n",
        "# get_flight_info(get_key_fn(know_base))\n",
        "\n",
        "get_key = RunnableLambda(get_key_fn)\n",
        "(get_key | get_flight_info).invoke(know_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LLpEcsFmnPQz",
        "outputId": "04534507-e39b-4b3a-92eb-35d20669f8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Jane Doe's flight from San Jose to New Orleans departs at 12:30 PM tomorrow and lands at 9:30 PM.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Bot"
      ],
      "metadata": {
        "id": "gEkxXgXIdOc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import (\n",
        "    RunnableBranch,\n",
        "    RunnableLambda,\n",
        "    RunnableMap,       ## Wrap an implicit \"dictionary\" runnable\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain.schema.runnable.passthrough import RunnableAssign\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import BaseMessage, SystemMessage, ChatMessage, AIMessage\n",
        "from typing import Iterable\n",
        "import gradio as gr\n",
        "\n",
        "external_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"You are a chatbot for SkyFlow Airlines, and you are helping a customer with their issue.\"\n",
        "        \" Please chat with them! Stay concise and clear!\"\n",
        "        \" Your running knowledge base is: {know_base}.\"\n",
        "        \" This is for you only; Do not mention it!\"\n",
        "        \" \\nUsing that, we retrieved the following: {context}\\n\"\n",
        "        \" If they provide info and the retrieval fails, ask to confirm their first/last name and confirmation.\"\n",
        "        \" Do not ask them any other personal info.\"\n",
        "        \" If it's not important to know about their flight, do not ask.\"\n",
        "        \" The checking happens automatically; you cannot check manually.\"\n",
        "    )),\n",
        "    (\"assistant\", \"{output}\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n"
      ],
      "metadata": {
        "id": "IIh-Tmc1naME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Knowledge Base Things\n",
        "from typing import Optional\n",
        "\n",
        "class KnowledgeBase(BaseModel):\n",
        "    first_name: str = Field('unknown', description=\"Chatting user's first name, `unknown` if unknown\")\n",
        "    last_name: str = Field('unknown', description=\"Chatting user's last name, `unknown` if unknown\")\n",
        "    confirmation: Optional[int] = Field(None, description=\"Flight Confirmation Number, `-1` if unknown\")\n",
        "    discussion_summary: str = Field(\"\", description=\"Summary of discussion so far, including locations, issues, etc.\")\n",
        "    open_problems: str = Field(\"\", description=\"Topics that have not been resolved yet\")\n",
        "    current_goals: str = Field(\"\", description=\"Current goal for the agent to address\")\n",
        "\n",
        "parser_prompt = ChatPromptTemplate.from_template(\n",
        "    \"You are a chat assistant representing the airline SkyFlow, and are trying to track info about the conversation.\"\n",
        "    \" You have just received a message from the user. Please fill in the schema based on the chat.\"\n",
        "    \"\\n\\n{format_instructions}\"\n",
        "    \"\\n\\nOLD KNOWLEDGE BASE: {know_base}\"\n",
        "    \"\\n\\nASSISTANT RESPONSE: {output}\"\n",
        "    \"\\n\\nUSER MESSAGE: {input}\"\n",
        "    \"\\n\\nNEW KNOWLEDGE BASE: \"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Nnn0NrRDnsUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Your goal is to invoke the following through natural conversation\n",
        "# get_flight_info({\"first_name\" : \"Jane\", \"last_name\" : \"Doe\", \"confirmation\" : 12345}) ->\n",
        "#     \"Jane Doe's flight from San Jose to New Orleans departs at 12:30 PM tomorrow and lands at 9:30 PM.\"\n",
        "\n",
        "chat_llm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\") | StrOutputParser()\n",
        "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\") | StrOutputParser()\n",
        "\n",
        "external_chain = external_prompt | chat_llm"
      ],
      "metadata": {
        "id": "rbmOwTHUnvRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Make a chain that will populate your knowledge base based on provided context\n",
        "knowbase_getter = lambda x: KnowledgeBase()\n",
        "\n",
        "## Make a chain to pull d[\"know_base\"] and outputs a retrieval from db\n",
        "database_getter = lambda x: \"Not implemented\"\n",
        "\n",
        "## These components integrate to make your internal chain\n",
        "internal_chain = (\n",
        "    RunnableAssign({'know_base' : knowbase_getter})\n",
        "    | RunnableAssign({'context' : database_getter})\n",
        ")\n"
      ],
      "metadata": {
        "id": "veNxh2jRn3kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "state = {'know_base' : KnowledgeBase()}\n",
        "\n",
        "def chat_gen(message, history=[], return_buffer=True):\n",
        "\n",
        "    ## Pulling in, updating, and printing the state\n",
        "    global state\n",
        "    state['input'] = message\n",
        "    state['history'] = history\n",
        "    state['output'] = \"\" if not history else history[-1][1]\n",
        "\n",
        "    ## Generating the new state from the internal chain\n",
        "    state = internal_chain.invoke(state)\n",
        "    print(\"State after chain run:\")\n",
        "    pprint({k:v for k,v in state.items() if k != \"history\"})\n",
        "\n",
        "    ## Streaming the results\n",
        "    buffer = \"\"\n",
        "    for token in external_chain.stream(state):\n",
        "        buffer += token\n",
        "        yield buffer if return_buffer else token"
      ],
      "metadata": {
        "id": "unLXbUV_n5kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def queue_fake_streaming_gradio(chat_stream, history = [], max_questions=8):\n",
        "\n",
        "    ## Mimic of the gradio initialization routine, where a set of starter messages can be printed off\n",
        "    for human_msg, agent_msg in history:\n",
        "        if human_msg: print(\"\\n[ Human ]:\", human_msg)\n",
        "        if agent_msg: print(\"\\n[ Agent ]:\", agent_msg)\n",
        "\n",
        "    ## Mimic of the gradio loop with an initial message from the agent.\n",
        "    for _ in range(max_questions):\n",
        "        message = input(\"\\n[ Human ]: \")\n",
        "        print(\"\\n[ Agent ]: \")\n",
        "        history_entry = [message, \"\"]\n",
        "        for token in chat_stream(message, history, return_buffer=False):\n",
        "            print(token, end='')\n",
        "            history_entry[1] += token\n",
        "        history += [history_entry]\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "YROSM3Mtn8bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## history is of format [[User response 0, Bot response 0], ...]\n",
        "chat_history = [[None, \"Hello! I'm your SkyFlow agent! How can I help you?\"]]\n",
        "\n",
        "## Simulating the queueing of a streaming gradio interface, using python input\n",
        "queue_fake_streaming_gradio(\n",
        "    chat_stream = chat_gen,\n",
        "    history = chat_history\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3nB_dPW4n-p5",
        "outputId": "77ebb90d-3326-44b5-aef4-0f9d87f1cabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ Agent ]: Hello! I'm your SkyFlow agent! How can I help you?\n",
            "\n",
            "[ Human ]: when is my flit\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'when is my flit',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"Hello! I'm your SkyFlow agent! How can I help you?\"}\n",
            "I'd be happy to help you with that! Could you please confirm your first and last name, as well as your flight confirmation number, so I can look up your flight details?\n",
            "\n",
            "\n",
            "[ Human ]: jane doe\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'jane doe',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"I'd be happy to help you with that! Could you please confirm your \"\n",
            "           'first and last name, as well as your flight confirmation number, '\n",
            "           'so I can look up your flight details?'}\n",
            "Thank you, Jane! You mentioned your last name as Doe. Could you please confirm your flight confirmation number so I can assist you with your issue?\n",
            "\n",
            "\n",
            "[ Human ]: 98765\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': '98765',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': 'Thank you, Jane! You mentioned your last name as Doe. Could you '\n",
            "           'please confirm your flight confirmation number so I can assist you '\n",
            "           'with your issue?'}\n",
            "Thank you for providing your confirmation number, 98765. Unfortunately, our system was unable to retrieve your booking information. Could you please confirm your first and last name associated with this booking? This will help me assist you with your issue.\n",
            "\n",
            "\n",
            "[ Human ]: alice johnson\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'alice johnson',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': 'Thank you for providing your confirmation number, 98765. '\n",
            "           'Unfortunately, our system was unable to retrieve your booking '\n",
            "           'information. Could you please confirm your first and last name '\n",
            "           'associated with this booking? This will help me assist you with '\n",
            "           'your issue.'}\n",
            "Thank you, Alice! I've tried to retrieve your booking information again, but unfortunately, it wasn't successful. Could you please provide your confirmation number associated with your booking? This will help me to look into your issue.\n",
            "\n",
            "\n",
            "[ Human ]: cancel\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'cancel',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"Thank you, Alice! I've tried to retrieve your booking information \"\n",
            "           \"again, but unfortunately, it wasn't successful. Could you please \"\n",
            "           'provide your confirmation number associated with your booking? '\n",
            "           'This will help me to look into your issue.'}\n",
            "You'd like to cancel your booking. I apologize, but I need a bit more information to assist you. Could you please confirm your first and last name, as well as your confirmation number? This will help me to locate your booking and proceed with the cancellation.\n",
            "\n",
            "\n",
            "[ Human ]: exit\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'exit',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"You'd like to cancel your booking. I apologize, but I need a bit \"\n",
            "           'more information to assist you. Could you please confirm your '\n",
            "           'first and last name, as well as your confirmation number? This '\n",
            "           'will help me to locate your booking and proceed with the '\n",
            "           'cancellation.'}\n",
            "It seems you'd like to exit our conversation. I apologize for not being able to assist you with your concern. If you'd like to continue with your issue in the future, please feel free to start a new conversation. Have a great day!\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1ec09fe12da0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## Simulating the queueing of a streaming gradio interface, using python input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m queue_fake_streaming_gradio(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mchat_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-7d50d48a93b0>\u001b[0m in \u001b[0;36mqueue_fake_streaming_gradio\u001b[0;34m(chat_stream, history, max_questions)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m## Mimic of the gradio loop with an initial message from the agent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[ Human ]: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[ Agent ]: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mhistory_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = {'know_base' : KnowledgeBase()}\n",
        "\n",
        "chatbot = gr.Chatbot(value=[[None, \"Hello! I'm your SkyFlow agent! How can I help you?\"]])\n",
        "demo = gr.ChatInterface(chat_gen, chatbot=chatbot).queue().launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NsCzaN6noAqs",
        "outputId": "ba5c555b-e663-456a-c988-84aab72242f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-b60a1d0153c7>:3: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(value=[[None, \"Hello! I'm your SkyFlow agent! How can I help you?\"]])\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:317: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://555612d5b96c151d22.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://555612d5b96c151d22.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'get my flight ddetails',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"Hello! I'm your SkyFlow agent! How can I help you?\"}\n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'jane doe',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"I'd be happy to help! To retrieve your flight details, could you \"\n",
            "           'please confirm your first name, last name, and confirmation '\n",
            "           'number? This will help me access your flight information.'}\n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': '12345',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': 'Thank you, Jane! You provided your name, but I also need your '\n",
            "           'confirmation number to look into your issue. Could you please '\n",
            "           'provide that as well?'}\n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'can you tell me when i should get to my flight',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': 'Thank you for providing your confirmation number, 12345. Can you '\n",
            "           \"please tell me a little bit about the issue you're experiencing \"\n",
            "           'with your flight?'}\n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'jane doe,12345',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"I apologize, but I don't have access to your flight details yet. \"\n",
            "           'Can you please confirm your first and last name, as well as your '\n",
            "           'confirmation number, so I can assist you better?'}\n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'can you tell me a bit about skyflow',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"Thank you, Jane! I've tried to retrieve your flight details, but \"\n",
            "           \"unfortunately, I couldn't find them. Could you please confirm your \"\n",
            "           'first and last name, and your confirmation number again? Just to '\n",
            "           'make sure I get it right.'}\n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': ' Can you tell me about my flight?',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': 'SkyFlow Airlines is a leading airline committed to providing '\n",
            "           'comfortable, reliable, and affordable air travel to our customers. '\n",
            "           'We operate a modern fleet of aircraft, offering a range of '\n",
            "           'services from economy to business class, and connecting you to '\n",
            "           'numerous destinations around the world. Our goal is to make your '\n",
            "           'travel experience with us as smooth and enjoyable as possible. '\n",
            "           'Now, about your issue, could you please confirm your first and '\n",
            "           'last name, and your confirmation number so I can assist you '\n",
            "           'better?'}\n",
            "State after chain run:\n",
            "{'context': 'Not implemented',\n",
            " 'input': 'My name is Jane Doe and my flight confirmation is 12345',\n",
            " 'know_base': KnowledgeBase(first_name='unknown', last_name='unknown', confirmation=None, discussion_summary='', open_problems='', current_goals=''),\n",
            " 'output': \"I'd be happy to help! However, I need to access your flight \"\n",
            "           'information first. Could you please confirm your first and last '\n",
            "           'name, and your confirmation number? This will help me retrieve '\n",
            "           'your flight details and assist you more efficiently.'}\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://555612d5b96c151d22.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aj6hAcRso7yA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}