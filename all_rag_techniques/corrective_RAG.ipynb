{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CRAG(Corrective RAG)\n",
        "Corrective retrieval-augmented generation (CRAG) is an improved version of RAG that aims to make language models more accurate.\n",
        "\n",
        "While traditional RAG simply uses retrieved documents to help generate text, CRAG takes it a step further by actively checking and refining these documents to ensure they are relevant and accurate. This helps reduce errors or hallucinations where the model might produce incorrect or misleading information."
      ],
      "metadata": {
        "id": "4WiuPXMtcXry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup"
      ],
      "metadata": {
        "id": "UrBXU8E5cuoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph tavily-python"
      ],
      "metadata": {
        "id": "cAZplh9VcieD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "_set_env(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRKf3HTsciam",
        "outputId": "4373b1f8-bb1b-44a5-86e6-0446370b5247"
      },
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setup proxy Knowledge Base"
      ],
      "metadata": {
        "id": "YZPKjleBciQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "urls = [\n",
        "    \"https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------\",\n",
        "    \"https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------\",\n",
        "    \"https://medium.com/@aakuskar.980/ai-agents-the-invisible-workforce-revolutionizing-our-world-a2905367f725?source=user_profile_page---------3-------------5c9ca647dacc----------------------\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0)\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    collection_name=\"proxy_knowledge_base\",\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "AlGDCQ8jciJm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Set up a RAG chain"
      ],
      "metadata": {
        "id": "0pw7zo_qciGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "rag_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "rag_chain = rag_prompt | rag_llm | StrOutputParser()\n",
        "\n",
        "print(rag_prompt.messages[0].prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJQ7QKPDciDx",
        "outputId": "8a9ba50c-f79a-4dd9-e96f-c38e917c3106"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: {question} \n",
            "Context: {context} \n",
            "Answer:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the question you want to ask\n",
        "question = \"What is LSTM?\"\n",
        "\n",
        "# Now invoke the RAG chain with the defined question\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(\"Question: %s\" % question)\n",
        "print(\"----\")\n",
        "print(\"Documents:\\\\n\")\n",
        "print('\\\\n\\\\n'.join(['- %s' % x.page_content for sublist in docs for x in sublist]))\n",
        "print(\"----\")\n",
        "print(\"Final answer: %s\" % generation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzHgmbDciBY",
        "outputId": "10aaa6a7-d798-4959-bc6e-dd4ef6afc679"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is LSTM?\n",
            "----\n",
            "Documents:\\n\n",
            "- Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya AkFollow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an essay.The Problem: Lack of Memory in Basic Neural NetworksHumans don’t start thinking from scratch all the time. As you read this essay, you’re connecting each new idea to previous ones, drawing on your memory of past experiences or information. But traditional neural networks don’t have this capability. Imagine trying to track events in a movie, but each new scene makes you forget the ones that came before. This is where LSTM (Long Short-Term Memory) comes in.LSTM: A Smarter Memory for Neural NetworksThink of LSTM as the super-smart version of that dumb friend. LSTM networks are designed to remember important information from the past and use it to understand the present. It’s like giving your friend a notebook to jot down key points during the movie, so they can refer to it later.So, what makes LSTM so powerful? It’s simple: LSTMs are neural networks with a good memory! They’re great at remembering what’s important from long sequences of data, like understanding language, predicting the next scene in a movie, or even composing music.Before jumping into LSTMs lets first understand little about RNNs .Recurrent Neural Networks (RNNs): The First Step Toward MemoryAn RNN is a type of neural network designed to handle sequences of data — like sentences, movie scenes, or even stock prices over time. The key idea behind RNNs is that they have a loop in them, allowing information to flow from one step to the next, similar to how our memory works.However, while RNNs were a step forward in understanding sequential data, they have some important limitations. Let’s talk about these challenges and why LSTMs were introduced.Simple RNNIn the above diagram, a chunk of neural network, A , looks at some input xt and outputs a value ht. A loop allows information to be passed from one step of the network to the next.If LSTMs are the super-smart friends with great memory, RNNs are their simpler cousins who try to remember things but aren’t as good at it. Still, they’re pretty cool and important to understand!In the last few years, RNN are successfully applied to a variety of tasks like speech recognition, language modeling, translation, image captioning but RNN have some dependencies, can you guess what the problem with RNNs is and why LSTM were discovered lets see.The Problem with RNNs: Long-Term DependenciesRNNs excel at processing short sequences of data. For example, understanding the last few words of a sentence or a couple of scenes in a movie. But when it comes to longer sequences (like a full-length movie or a long essay), RNNs start to forget important details from earlier on. This issue is called the Short-Term Memory Problem.But that’s not all, RNNs also suffer from the Vanishing Gradient Problem. This is a technical issue where the network’s memory fades over time, like a whisper getting weaker as it passes through a long line of people. When this happens, important information is lost, making RNNs struggle with long sequences.Sometimes we only need to look at some of the past information for the ongoing task ,which is quiet simple even the humans could remember past few things easily but they find it difficult to remember the long memory actions as the gap grows we are unable to connect the dots, similarly RNNs are unable to learn to connect the information, RNNs are great at handling short sequences, they struggle with longer ones this problem is Short-Term Memory, RNNs are like someone who can only remember the last few things they heard. If the sequence gets too long (like a whole book or a long movie), they start to forget the important stuff from the beginning.This is the main reason LSTMs were introduced, they don’t have this problem!LSTMs: The Solution to RNN’s Memory ProblemLSTMs were introduced by Hochreiter & Schmidhuber in 1997 to address the problems that RNNs face. If RNNs are like someone with a poor memory, LSTMs are like an organized librarian who never forgets important details. They can remember information for much longer and make better decisions about what to keep and what to discard.LSTMs were explicitly designed to solve the long-term dependency problem, and remembering information over long periods is their default behavior, not something they have to learn!RNN modelLSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.LSTM modelHow LSTMs Work: The Core IdeaLSTMs (Long Short-Term Memory networks) can be thought of like a librarian managing a library of information. The three gates in an LSTM control how the information is managed and flow through the network, similar to how a librarian would decide what to keep, discard, or access at any given time. So we can say at the heart of LSTMs is a cell state, which is like a conveyor belt carrying information from one time step to the next. The cell state helps the network retain long-term dependencies, which is essential for tasks like language modeling, speech recognition, and time-series prediction.LSTMs manage the flow of information through the network using gates, similar to how a librarian decides which books to keep, discard, or refer to. Let’s break it down:1. Forget Gate: Deciding What to Let GoThe forget gate looks at the previous output and the current input and decides what information to forget. If something is outdated or irrelevant, it’s discarded. This is like the librarian reviewing old books and deciding which ones no longer need to be stored.2. Input Gate: Deciding What to KeepThe input gate decides what new information to store in the memory. The librarian assesses incoming books and chooses which ones are worth keeping. This gate works with both a sigmoid function (which decides which information to add) and a tanh function (which creates candidate values for the new information).3. Output Gate: Deciding What to ShareThe output gate determines what information should be passed on to the next time step. It decides which parts of the memory are relevant and should be shared, much like the librarian checking out books to others.In this way, the LSTM helps the model maintain and modify its “memory” over time, allowing it to remember important information while forgetting irrelevant detailsA Detailed Look at the LSTM ProcessNow that we know how the gates work, let’s walk through the entire process step by step:Forget Gate: Decides what to forget from the previous cell state.Input Gate: Decides what new information to add.Cell State Update: The forget and input gates work together to update the cell state.Output Gate: Decides what part of the memory should be passed to the next time step.Long Short-Term Memory (LSTM) networks have become a fundamental architecture in the field of deep learning, especially for tasks involving sequential data, like natural language processing or time series prediction. What sets LSTMs apart from traditional neural networks and other types of recurrent neural networks (RNNs) is their ability to capture long-term dependencies.One of the core features that make LSTMs so effective are the gates. Gates control the flow of information at each time step, deciding what to remember, what to forget, and what to output. Essentially, gates act as filters, allowing only the necessary information to pass through the network at each stage.Think of the cell state as a conveyor belt running through the entire network. This conveyor belt carries information from one time step to the next, the cell state allows information to flow relatively unchanged across time steps. This helps retain long-term dependencies in the data.Gates are a way to optionally let information throughGates in an LSTM control the flow of information at each time step. They allow the network to decide what to remember, what to forget, and what to output.A gate is essentially a mechanism that acts like a filter. It decides whether or not certain information should pass through based on the current input and the previous state.How Gates WorkEach gate in an LSTM consists of two key elements:Sigmoid Activation Function:The sigmoid function takes the current input and previous output, passing them through a neural network layer. It produces values between 0 and 1, which determine how much information should be allowed through. A value of 0 means “don’t let any information through,” while a value of 1 means “let all information through.”2. Pointwise Multiplication:After applying the sigmoid function, the output is combined with the relevant data (such as the cell state or input) through pointwise multiplication. This operation effectively scales the information allowed through, based on the sigmoid’s output.A Step-by-Step Walkthrough of the LSTM ProcessLet’s break down how information flows through an LSTM network.Forget Gate:The forget gate is the first step in determining what information to discard from the cell state. It takes in the previous hidden state ht−1​ and the current input xt​, passing them through a sigmoid function. The output is a vector with values between 0 and 1, indicating which parts of the previous cell state Ct−1 should be remembered and which should be forgotten. A value of 1 means “keep it,” while 0 means “forget it.”The output of the forget gate is a vector ft​ (with values between 0 and 1 for each element of the previous cell state Ct−1). This vector is then multiplied element-wise by the previous cell state Ct−1 to determine which parts of the memory should be kept and which should be discarded.Ct′​ = ft​∗Ct−1​ (Ct′​ is the modified cell state after the forget gate has done its job.)2. Input Gate:After deciding what to forget, the next step is to determine what new information to store in the cell state. This is done by the input gate, which is composed of two parts: the input gate layer and the candidate cell state.Input Gate Layer: The input gate layer uses a sigmoid function on ht−1 and xt to decide how much new information should be added to the cell state.The output of the sigmoid function is a vector with values between 0 and 1, just like the forget gate. This tells us how much of the new information should be added to the cell state.— A value of 0 means “don’t add anything here” (we won’t update this part of the cell state).— A value of 1 means “fully add new information here” (we’ll update this part of the cell state fully).2. Candidate Cell State (tanh Layer):The next part is generating candidate values, which are potential updates to the cell state. The network needs to decide what new information should be added to the state, so it creates a candidate vector using the tanh activation function.The C~t​ vector represents new information (e.g., the “gender of the new subject” in your language model example). This candidate vector is created by passing both ht−1 and xt​ through a tanh function, which produces values between -1 and 1. This ensures that the new information is appropriately scaled.3. Combining the Input Gate and Candidate Values:Now, we combine the outputs of the input gate (which decides how much new information we should add) and the candidate values (which represent the new information).The input gate vector it​ tells the model how much of the new information in C~t​ should be added to the current cell state. We multiply the input gate output by the candidate values to get the final update for the cell state.ft​ × Ct−1​ is the part of the cell state that we decided to retain from the previous time step.it × C~t ​ is the new information we’ve decided to incorporate.3. Output Gate:The final step is to determine what information should be output from the cell state. This is done by the output gate. First, the output gate uses a sigmoid function on ht−1 and xt​ to decide which parts of the cell state should be output. Then, the cell state is passed through a tanh function to push the values to be between -1 and 1.Finally, the output of the output gate is multiplied by the tanh-transformed cell state to produce the output at the current time step:ht=ot×tanh⁡(Ct)where ot​ is the output gate’s decision of what information to output.Variants of LSTMOver time, several variants of LSTMs have been developed to address specific needs in different applications:Gated Recurrent Unit (GRU):The GRU is a simplified version of the LSTM. It combines the forget and input gates into a single gate called the “update gate.” This reduces the complexity of the model while still allowing it to perform well on tasks with less complex dependencies. GRUs also combine the cell state and hidden state into one vector, streamlining the architecture.2. Bidirectional LSTM (BiLSTM):A Bidirectional LSTM processes the input sequence in both forward and backward directions. This allows the model to capture information from both past and future contexts at each time step. Two LSTMs are trained in parallel — one processes the sequence from left to right, while the other processes it from right to left. The outputs of these two LSTMs are then combined to form the final output at each time step.ConclusionLSTMs (Long Short-Term Memory networks) are a type of RNN (Recurrent Neural Network) that work really well for many tasks, like language processing. Even though LSTMs look complicated when written as equations, going through them step by step can make them easier to understand. They were a big improvement over earlier RNNs and have made a huge impact on what we can do with these networks.However, researchers think there might be an even bigger step forward coming, and that step could be attention. With attention, an RNN can pick which pieces of information to focus on at each step, rather than looking at all the information equally(transformers). For example, in image captioning, the RNN could look at different parts of an image as it generates each word of the caption. This idea of using attention has already led to some exciting results and is expected to bring even more breakthroughs.Besides attention, there are other promising areas in RNN research, such as Grid LSTMs and using RNNs in generative models. These areas are showing a lot of potential, and researchers are excited about what the future holds for RNNs and deep learning in general!Coming Up Next: The Rise of TransformersWhile LSTMs have been a staple in sequential data modeling, a new architecture has rapidly gained popularity in recent years — Transformers. In the next section, we’ll explore how Transformers work, why they outperform LSTMs in many modern NLP tasks, and their groundbreaking role in models like GPT and BERT. We’ll also discuss the key principles behind attention mechanisms and how they revolutionized the way we process sequences. Stay tuned to learn more!Lstm NetworksDeep LearningRnnWorking----FollowWritten by Aditya Ak0 followers·5 followingLeveraging data science and machine learning to solve complex problems and make life better.FollowNo responses yetHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\\n\\n- What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | MediumOpen in appSign upSign inWriteSign upSign inWhat is the Model Context Protocol (MCP)?Aditya AkFollow5 min read·Mar 24, 2025--ListenShareIn the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI assistants to directly interact with various services. This creates new possibilities for AI applications to access real-time data, interact with external systems, and use specialized tools, all through a standardized interface.Think of MCP as the USB-C for AI — a universal connector that allows AI models to seamlessly integrate with different tools and data sources.Model Context Protocol serves as a critical communication bridge between AI models and external systems, enabling AI assistants to interact directly with various services through a standardized interface. This protocol was designed to address the inherent limitations of standalone AI models by providing them with pathways to access real-time data, perform actions in external systems, and leverage specialized tools beyond their built-in capabilities.The fundamental architecture of MCP consists of client-server communication where the AI model (client) can send requests to specialized servers that handle specific service integrations, process these requests, and return formatted results that the AI can incorporate into its responses. This design pattern enables AI systems to maintain their core reasoning capabilities while extending their functional reach into practical applications that require interaction with external systems and databasesMCP has the potential to function as a universal interface, think of it as the virtual / software version of USB-C for AI. Enabling seamless, secure and scalable data exchange between LLMs/AI Agents and external resources. MCP uses a client-server architecture where MCP hosts (AI applications) communicate with MCP servers (data/tool providers).Developers can use MCP to build reusable, modular connectors, with pre-built servers available for popular platforms, creating a community-driven ecosystem. MCP’s open-source nature encourages innovation, allowing developers to extend its capabilities while maintaining security through features like granular permissions. Ultimately, MCP aims to transform AI Agents from isolated chatbots into context-aware, interoperable systems deeply integrated into digital environments. Key elements from the Model Context Protocol:Standardization: MCP provides a standardized way for language models to interact with tools, promoting interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use Case: Integrating Claude AI with MCPOne of the coolest aspects of MCP is how it can be combined with existing AI tools, like Claude from Anthropic, to create more powerful applications. Let’s look at a simple example of integrating MCP with Claude AI using Chainlit and the Claude API.ImplementationStep 1: Loading MCP ToolsFirst, we need to ensure all the MCP tools are loaded into the Chainlit session. This step allows the AI to access external tools for its tasks.First thing we need to ensure is our MCP tools are listed and loaded to our chainlit session. As you install any MCP server , you need to ensure that all the tools of those associated MCP servers are added to your session..on_chat_start async def start_chat():    client = ChatClient()    cl.user_session.set(\"messages\", [])    cl.user_session.set(\"system_prompt\", SYSTEM_PROMPT)@cl.on_mcp_connect async def on_mcp(connection, session: ClientSession):    result = await session.list_tools()    tools = [{\"name\": t.name, \"description\": t.description, \"parameters\": t.inputSchema} for t in result.tools]    mcp_tools = cl.user_session.get(\"mcp_tools\", {})    mcp_tools[connection.name] = tools    cl.user_session.set(\"mcp_tools\", mcp_tools)Step 2: Flattening ToolsNext, we flatten the list of tools, which will be passed to Claude AI during the chat session. In this case for each message we pass the loaded MCP server session tools into chat session after flattening it.def flatten(xss):    return [x for xs in xss for x in xs]@cl.on_message async def on_message(message: cl.Message):    mcp_tools = cl.user_session.get(\"mcp_tools\", {})    tools = flatten([tools for _, tools in mcp_tools.items()])    tools = [{\"type\": \"function\", \"function\": tool} for tool in tools]    client = ChatClient()    client.messages = cl.user_session.get(\"messages\", [])    msg = cl.Message(content=\"\")    async for text in client.generate_response(human_input=message.content, tools=tools):        await msg.stream_token(text)    cl.user_session.set(\"messages\", client.messages)Step 3: Calling the ToolHere’s how you can call an MCP tool and use it to fetch responses during the conversation, basically call the MCP session to execute the tool..step(type=\"tool\") async def call_tool(mcp_name, function_name, function_args):    try:        print(f\"Function Name: {function_name} Function Args: {function_args}\")        mcp_session, _ = cl.context.session.mcp_sessions.get(mcp_name)        func_response = await mcp_session.call_tool(function_name, function_args)    except Exception as e:        traceback.print_exc()        func_response = json.dumps({\"error\": str(e)})    return str(func_response.content)Step 4: Generate Responses Using ToolsNow that we’ve integrated MCP tools, the Claude AI assistant can call these tools, process responses, and continue the conversation.async def generate_response(self, human_input, tools, temperature=0):    print(f\"human_input: {human_input}\")    self.messages.append({\"role\": \"user\", \"content\": human_input})    response_stream = await self.client.chat.completions.create(        model=self.deployment_name,        messages=self.messages,        tools=tools,        parallel_tool_calls=False,        stream=True,        temperature=temperature    )    try:        async for token in self.process_response_stream(response_stream, tools, temperature):            yield token    except GeneratorExit:        returnConclusion: The Future of AI with MCPThe Model Context Protocol (MCP) is a game-changer in AI integration. By providing a universal interface, it allows AI models to break free from their limitations and interact with external tools and data. With its flexible, secure, and scalable design, MCP makes it easier for developers to build context-aware, powerful AI systems.With the Claude AI model now enhanced by MCP, you can build smarter, more interactive AI applications that leverage both real-time data and specialized external tools.Ready to explore? Check out the full demo and start integrating MCP with Claude in your AI projects today!Thank You And keep Exploring!----FollowWritten by Aditya Ak0 followers·5 followingLeveraging data science and machine learning to solve complex problems and make life better.FollowNo responses yetHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\\n\\n- AI Agents: The Invisible Workforce Revolutionizing Our World | by Aditya Ak | Mar, 2025 | MediumOpen in appSign upSign inWriteSign upSign inSuper smart multi-agent JARVISAI Agents: The Invisible Workforce Revolutionizing Our WorldAditya AkFollow7 min read·Mar 12, 2025--ListenShareArtificial Intelligence (AI) has come a long way, moving from science fiction to a key part of our everyday lives. One of the most exciting developments in AI is the rise of AI agents. These smart systems are transforming industries, boosting productivity, and helping create a smarter future. But what exactly are AI agents, and how are they changing the world of technology?It’s fun to think about! Many of the cool technologies we see in movies, like flying cars, super-smart robots, and virtual reality worlds, seem like pure fantasy, but some of them are actually becoming more possible thanks to advancements in science and tech. Don’t forget about J.A.R.V.I.S. the super smart multi-agentic system we seen in Iron Man , now would it be really possible to create a technology like that. What I think is It might take some time, but we’re heading in the direction where J.A.R.V.I.S.-like assistants could be a reality! The future of AI holds endless possibilities, and it’s not too far-fetched to think we might get close to having a helpful AI companion. What other movie tech would you like to see become reality?Also, It’s exciting to think about what the future holds but not all movie tech is practical or possible, a lot of it is sparking real-world innovation? Let’s dive in and see how they’re making an impact and what the future might look like!Understanding AI AgentsAI agents are like digital problem-solvers with the ability to make decisions and act on their own, all aimed at completing a task or goal. They can be as simple as chatbots answering your questions or as advanced as systems that help companies streamline operations, predict trends, or even control self-driving cars. What sets them apart is their ability to learn from their experiences, meaning they get better the more they interact with their environment.Here’s how they work:Perception: AI agents use sensors or data input (like cameras, microphones, or software logs) to understand what’s happening around them.Processing Information: Once they gather data, they analyze it using algorithms — think of it like their brain figuring out the best action to take.Taking Action: Based on their analysis, AI agents perform tasks like making recommendations, answering questions, or controlling systems. Over time, they adjust their strategies using machine learning to improve their performance.Technologies like Natural Language Processing (NLP) help them understand human language (like how Siri or Alexa understand what you say), deep learning allows them to process vast amounts of data, and reinforcement learning helps them make decisions based on rewards (just like learning through trial and error).As AI agents evolve, their potential grows, impacting everything from customer service to healthcare, manufacturing, and even entertainment. It’s fascinating to think about how they’ll continue to shape our world!The Transformation of the Tech IndustryAI agents are driving an unprecedented transformation in the tech industry, affecting everything from software development to customer service. Some of the key areas where AI agents are making an impact include:1. Automation and EfficiencyAI agents automate repetitive tasks, allowing developers, IT professionals, and businesses to focus on high-value work. They optimize workflows in software engineering, automate debugging, and even assist in writing and testing code, significantly reducing development time. For instance, companies like Google and Microsoft use AI-powered tools like GitHub Copilot to aid developers, accelerating coding efficiency and innovation.2. Enhanced Customer ExperienceVirtual assistants and AI-powered chatbots provide 24/7 support, improving customer interactions with personalized recommendations and real-time solutions. Imagine a scenario where an AI assistant remembers a customer’s past purchases and suggests relevant items — this is already happening with Amazon Alexa and Google Assistant. These systems continue to evolve, offering seamless experiences across multiple platforms.3. Data-Driven Decision MakingAI agents analyze vast amounts of data in real-time, enabling businesses to make informed decisions faster. Predictive analytics, powered by AI, is transforming industries like finance, healthcare, and retail, allowing companies to anticipate market trends and optimize strategies. Take Netflix, for example — its recommendation engine, powered by AI, keeps users engaged by curating personalized content based on viewing habits.4. Cybersecurity and Threat DetectionAI-driven security agents monitor network activity, detect anomalies, and prevent cyber threats before they escalate. With the increasing complexity of cyberattacks, AI is becoming an essential ally in securing digital infrastructures. Darktrace, for example, is an AI cybersecurity company that detects cyber threats by learning an organization’s normal behavior and flagging unusual activities in real-time.5. AI in Software DevelopmentAI agents are reshaping how software is developed, maintained, and improved. Tools like GitHub Copilot and OpenAI Codex assist developers by suggesting code snippets, reducing human error, and accelerating the development cycle. These AI agents are also being used in bug detection and software testing, ensuring smoother product rollouts.Real-World AI Agents Making an ImpactAI agents are already playing a transformative role in various industries. Some of the most impactful AI agents in the market and also some which i personally use on daily basis include:ChatGPT (OpenAI): Revolutionizing content creation, customer support, and programming assistance with conversational AI.Tesla Autopilot: An advanced driver-assistance AI agent that enhances road safety and drives the future of autonomous vehicles.Google Assistant & Amazon Alexa: Enhancing user experiences with voice-based AI for smart home automation, searches, and daily tasks.IBM Watson: Transforming healthcare and business intelligence by analyzing vast data sets and providing insights.DeepMind AlphaFold: Advancing scientific research by predicting protein structures, accelerating drug discovery and medical breakthroughs.Darktrace: A cybersecurity AI agent that detects and responds to cyber threats in real-time, safeguarding businesses from sophisticated attacks.UiPath: Leading robotic process automation (RPA) with AI-driven software bots that streamline business operations.The Future of AI AgentsLooking ahead, AI agents are poised to become even more sophisticated, enhancing their ability to understand and interact with humans naturally. Some of the emerging trends and future possibilities include:Hyper-Personalization: AI agents will get better at tailoring experiences to individual needs, making everything from online shopping to healthcare more personal. Imagine an AI assistant that can help your doctor find the perfect treatment plan based on your medical history, lifestyle, and genetic data, or a digital marketing campaign that feels uniquely designed just for you.Human-AI Collaboration:Instead of replacing jobs, AI agents will enhance human abilities. In fields like architecture, design, or even research, AI could serve as a powerful collaborator. Think about an AI-powered assistant helping an architect design more efficient, sustainable buildings by predicting potential design flaws or suggesting creative alternatives.Advanced Reasoning: AI agents will evolve to go beyond processing data to performing advanced reasoning and even showing emotional intelligence. Imagine a virtual assistant that can not only provide factual answers but also recognize when you’re frustrated and adjust its tone or approach accordingly. These agents will become smarter and more human-like in their interactions.Decentralized AI: The integration of AI with blockchain and decentralized systems will create more secure and transparent AI-driven ecosystems.General AI (AGI): Future AI systems may move beyond narrow AI applications to exhibit human-like intelligence, enabling problem-solving and adaptability across a wide range of fields. Companies like DeepMind are already exploring AGI by training models to learn from experience.AI in Space Exploration: AI-driven autonomous systems will play a crucial role in deep space missions, planetary exploration, and optimizing spacecraft operations. NASA already employs AI agents to analyze satellite images and detect climate change patterns.AI-Powered Creativity: AI will contribute to art, music, and storytelling, generating new forms of creative expression in collaboration with humans. Tools like DALL·E and Runway ML are redefining digital artistry, producing AI-generated music and paintings that rival human creativity.AI and Quantum Computing: The combination of AI with quantum computing could unlock unprecedented computational power, solving complex problems in materials science, cryptography, and medicine. Imagine AI agents predicting drug effectiveness in seconds rather than years.As AI continues to evolve, it’s clear that the future holds incredible possibilities. Whether it’s changing the way we work, interact with technology, or explore the universe, AI agents will be a driving force in shaping tomorrow’s world. The best part? We’re just getting started!The Ethical Challenges of AI AgentsAI agents are undoubtedly shaping the future in exciting ways, but with these advancements come important ethical challenges that we can’t overlook. As AI becomes more integrated into our lives, it’s crucial to consider the societal implications and address these issues responsibly. Here are some of the main ethical challenges we’ll need to navigate:Bias in AI: AI agents learn from data, and if that data contains biases, AI can reinforce existing prejudices. Ensuring fairness and inclusivity in AI algorithms is critical.Privacy Concerns: AI systems collect and analyze massive amounts of personal data, raising concerns about surveillance and misuse.Job Displacement: Automation may replace certain jobs, requiring workforce adaptation and reskilling.Security Risks: As AI becomes more advanced, malicious actors can exploit it for cybercrimes, necessitating strong AI governance frameworks.The potential of AI agents is incredible, but they come with responsibilities. As we advance into a future where AI plays a central role, it’s important to address these ethical challenges thoughtfully, ensuring that AI is used for the benefit of all, while protecting against unintended consequences. Balancing innovation with ethics will be key to creating a fairer, safer, and more equitable world powered by AI.Final ThoughtsAI agents are much more than a passing trend — they are at the heart of a new era where intelligent automation and human-machine collaboration are changing the game. From helping with customer service to transforming healthcare, and even assisting in the exploration of distant planets, AI agents are making a profound impact on how we live and work.As the tech industry evolves, AI agents will continue to lead the way, driving innovation, enhancing productivity, and reshaping how we interact with technology. The future is undeniably AI-powered, and the exciting part is that it’s already happening.With AI advancing so rapidly, one thing is certain: the way humans and AI agents work together will define the future of many industries. This partnership has the potential to unlock new levels of creativity, efficiency, and innovation. But how we guide and control this powerful technology will determine whether it becomes a force for good or a disruptive challenge.The power is in our hands to shape the future. Let’s make the most of it and ensure AI continues to serve humanity’s best interests, paving the way for a brighter, smarter tomorrow.AIAgentsArtifiFutureRisk----FollowWritten by Aditya Ak0 followers·5 followingLeveraging data science and machine learning to solve complex problems and make life better.FollowNo responses yetHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "----\n",
            "Final answer: LSTM (Long Short-Term Memory) is a type of neural network designed to handle sequences of data. It has a good memory that allows it to remember important information from the past and use it to understand the present, making it great at remembering what's important from long sequences of data and capturing long-term dependencies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Set up a retrieval evaluator\n",
        "To improve the accuracy of the generated content, we set up a retrieval evaluator. This tool checks how relevant each retrieved document is to make sure only the most useful information is used."
      ],
      "metadata": {
        "id": "Udbv3IH0ch8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class RetrievalEvaluator(BaseModel):\n",
        "    \"\"\"Classify retrieved documents based on how relevant it is to the user's question.\"\"\"\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "retrieval_evaluator_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "structured_llm_evaluator = retrieval_evaluator_llm.with_structured_output(RetrievalEvaluator)\n",
        "\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a document retrieval evaluator that's responsible for checking the relevancy of a retrieved document to the user's question. \\\\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\\\n\n",
        "    Output a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\"\"\"\n",
        "\n",
        "retrieval_evaluator_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\\\n\\\\n {document} \\\\n\\\\n User question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "retrieval_grader = retrieval_evaluator_prompt | structured_llm_evaluator\n"
      ],
      "metadata": {
        "id": "jk7UHoX6ch6R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Setup question rewrite"
      ],
      "metadata": {
        "id": "mDwEM5iUch35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_rewriter_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a question re-writer that converts an input question to a better version that is optimized \\\\n\n",
        "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
        "\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Here is the initial question: \\\\n\\\\n {question} \\\\n Formulate an improved question.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "question_rewriter = re_write_prompt | question_rewriter_llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "IM6sUDk_ch1d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Search\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ],
      "metadata": {
        "id": "zqUxFq1SchzM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the graph state\n",
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        web_search: whether to add search\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    generation: str\n",
        "    web_search: str\n",
        "    documents: List[str]"
      ],
      "metadata": {
        "id": "pTIuzc3Fchwv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function nodes\n",
        "from langchain.schema import Document\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "    # Retrieval\n",
        "    documents = retriever.get_relevant_documents(question)\n",
        "    return {\"documents\": documents, \"question\": question}"
      ],
      "metadata": {
        "id": "idFAYyJechug"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # RAG generation\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
      ],
      "metadata": {
        "id": "l0d28FAli9Rm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    web_search = \"No\"\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke(\n",
        "            {\"question\": question, \"document\": d.page_content}\n",
        "        )\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "            continue\n",
        "    if len(filtered_docs) / len(documents) <= 0.7:\n",
        "        web_search = \"Yes\"\n",
        "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}"
      ],
      "metadata": {
        "id": "2gJ1SO66i-52"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_query(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased question\n",
        "    \"\"\"\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}"
      ],
      "metadata": {
        "id": "3QkecBY0jA1J"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    documents.append(web_results)\n",
        "    return {\"documents\": documents, \"question\": question}"
      ],
      "metadata": {
        "id": "WC8IkFHzjCdR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    state[\"question\"]\n",
        "    web_search = state[\"web_search\"]\n",
        "    state[\"documents\"]\n",
        "    if web_search == \"Yes\":\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\n",
        "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
        "        )\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE---\")\n",
        "        return \"generate\""
      ],
      "metadata": {
        "id": "8HXSJMq2jEby"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "workflow.add_node(\"grade_documents\", evaluate_documents)  # evaluate documents\n",
        "workflow.add_node(\"generate\", generate)  # generate\n",
        "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
        "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
        "\n",
        "# Build graph\n",
        "workflow.add_edge(START, \"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
        "workflow.add_edge(\"web_search_node\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "# Compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "80Z821eAjF56"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "gMyPb7FVjH39",
        "outputId": "1902074c-0293-4d9e-ad51-13093f391973"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "# Run\n",
        "inputs = {\"question\": \"What's is LSTM?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint(\"\\\\n---\\\\n\")\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqkm3hBAjJii",
        "outputId": "a5dc9c80-dfbc-42a5-b0af-2dc310d28274"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVE---\n",
            "\"Node 'retrieve':\"\n",
            "{ 'documents': [ Document(metadata={'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya AkFollow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya AkFollow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'language': 'en', 'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya Ak·Follow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya Ak·Follow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an')],\n",
            "  'question': \"What's is LSTM?\"}\n",
            "'\\\\n---\\\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: GENERATE---\n",
            "\"Node 'grade_documents':\"\n",
            "{ 'documents': [ Document(metadata={'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya AkFollow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya AkFollow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'language': 'en', 'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya Ak·Follow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya Ak·Follow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an')],\n",
            "  'question': \"What's is LSTM?\",\n",
            "  'web_search': 'No'}\n",
            "'\\\\n---\\\\n'\n",
            "---GENERATE---\n",
            "\"Node 'generate':\"\n",
            "{ 'documents': [ Document(metadata={'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya AkFollow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya AkFollow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'language': 'en', 'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya Ak·Follow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an'),\n",
            "                 Document(metadata={'title': 'Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | Medium', 'description': 'Understanding LSTM networks  so ,Imagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters.......', 'source': 'https://medium.com/@aakuskar.980/understanding-lstm-networks-a-simplified-explanation-3659be6b4923?source=user_profile_page---------0-------------5c9ca647dacc----------------------', 'language': 'en'}, page_content='Understanding LSTM Networks: A Simplified Explanation | by Aditya Ak | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding LSTM Networks: A Simplified ExplanationAditya Ak·Follow12 min read·Mar 3, 2025--ListenShareImagine you’re watching a movie. As the plot unfolds, you don’t forget what happened at the beginning, right? You remember the characters, their relationships, especially the actress, and how all of this helps you predict what will happen next. For example, if the hero loses their sword in the first scene, you know when they’ll pick it up later because your brain connects the dots!Now, think of a basic neural network as someone who watches the same movie but forgets everything after each scene. If you ask them, “Why is the hero fighting the villain?” they might say, “I don’t know, I forgot what happened earlier!” This is because basic neural networks process information step by step without retaining past information. They start from scratch every time, making it hard to understand things that depend on context — like a movie plot or even a sentence in an')],\n",
            "  'generation': 'LSTM (Long Short-Term Memory) is a type of neural network '\n",
            "                'that can remember past information and retain context over '\n",
            "                'time, unlike basic neural networks which process information '\n",
            "                'step by step without retaining past information. This allows '\n",
            "                'LSTMs to understand things that depend on context, like a '\n",
            "                'movie plot or a sentence in a language. LSTMs are designed to '\n",
            "                'handle the problem of vanishing gradients in basic neural '\n",
            "                'networks.',\n",
            "  'question': \"What's is LSTM?\"}\n",
            "'\\\\n---\\\\n'\n",
            "('LSTM (Long Short-Term Memory) is a type of neural network that can remember '\n",
            " 'past information and retain context over time, unlike basic neural networks '\n",
            " 'which process information step by step without retaining past information. '\n",
            " 'This allows LSTMs to understand things that depend on context, like a movie '\n",
            " 'plot or a sentence in a language. LSTMs are designed to handle the problem '\n",
            " 'of vanishing gradients in basic neural networks.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "# Run\n",
        "inputs = {\"question\": \"What are features of MCP?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint(\"\\\\n---\\\\n\")\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2z75jNcjMNb",
        "outputId": "4a7fdc3b-3ee5-490a-c0c6-37f7abc6860a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVE---\n",
            "\"Node 'retrieve':\"\n",
            "{ 'documents': [ Document(metadata={'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'language': 'en'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'language': 'en', 'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…', 'language': 'en', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'language': 'en', 'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use')],\n",
            "  'question': 'What are features of MCP?'}\n",
            "'\\\\n---\\\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: GENERATE---\n",
            "\"Node 'grade_documents':\"\n",
            "{ 'documents': [ Document(metadata={'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'language': 'en'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'language': 'en', 'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…', 'language': 'en', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'language': 'en', 'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use')],\n",
            "  'question': 'What are features of MCP?',\n",
            "  'web_search': 'No'}\n",
            "'\\\\n---\\\\n'\n",
            "---GENERATE---\n",
            "\"Node 'generate':\"\n",
            "{ 'documents': [ Document(metadata={'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'language': 'en'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'language': 'en', 'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…', 'language': 'en', 'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use'),\n",
            "                 Document(metadata={'source': 'https://medium.com/@aakuskar.980/what-is-the-model-context-protocol-mcp-f6e287d62adc?source=user_profile_page---------2-------------5c9ca647dacc----------------------', 'title': 'What is the Model Context Protocol (MCP)? | by Aditya Ak | Mar, 2025 | Medium', 'language': 'en', 'description': 'In the rapidly evolving world of AI, the Model Context Protocol (MCP) is gaining attention for a good reason. It acts as a communication bridge between AI models and external systems, enabling AI…'}, page_content='interoperability.Communication Methods: Supports multiple communication methods, including STDIO and SSE, for flexibility in tool integration.Tool Integration: Enables language models to use external tools, enhancing their functionality and applicability.How Does MCP Work?MCP operates on a client-server architecture:MCP Hosts: These are the AI applications or interfaces, such as IDEs, or AI tools, that seek to access data through MCP. They initiate requests for data or actions.MCP Clients: These are protocol clients that maintain a one-to-one connection with MCP servers, acting as intermediaries to forward requests and responses.MCP Servers: Lightweight programs that expose specific capabilities through the MCP, connecting to local or remote data sources. Examples include servers for file systems, databases, or APIs, each advertising their capabilities for hosts to utilize.Local Data Sources: These include the computer’s files, databases, and services that MCP servers can securely access, such as reading local documents or querying SQLite databases.Remote Services: External systems available over the internet, such as APIs, that MCP servers can connect to, enabling AI to interact with cloud-based tools or services.Use')],\n",
            "  'generation': 'MCP features include interoperability, communication methods '\n",
            "                '(such as STDIO and SSE), and tool integration, enabling '\n",
            "                'language models to use external tools and interact with local '\n",
            "                'and remote data sources.',\n",
            "  'question': 'What are features of MCP?'}\n",
            "'\\\\n---\\\\n'\n",
            "('MCP features include interoperability, communication methods (such as STDIO '\n",
            " 'and SSE), and tool integration, enabling language models to use external '\n",
            " 'tools and interact with local and remote data sources.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQUfnnRUjQ-B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}